{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we will do basic visualisation and analysis of the UCI breast cancer dataset. We will then apply various machine learning methods on the said dataset.\n",
    "\n",
    "This dataset helps you classify a patient as having breast cancer or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen # Used for opening link\n",
    "\n",
    "import matplotlib.pyplot as plt # Install if not installed\n",
    "import seaborn as sns # Install if not installed\n",
    "\n",
    "import sklearn # Install if not installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the UCI breast cancer dataset, which helps us predict whether or not a person has cancer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset using a link\n",
    "\n",
    "UCI_data_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n",
    "\n",
    "column_names = ['id_number', 'diagnosis', 'radius_mean', \n",
    "         'texture_mean', 'perimeter_mean', 'area_mean', \n",
    "         'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "         'concave_points_mean', 'symmetry_mean', \n",
    "         'fractal_dimension_mean', 'radius_se', 'texture_se', \n",
    "         'perimeter_se', 'area_se', 'smoothness_se', \n",
    "         'compactness_se', 'concavity_se', 'concave_points_se', \n",
    "         'symmetry_se', 'fractal_dimension_se', \n",
    "         'radius_worst', 'texture_worst', 'perimeter_worst',\n",
    "         'area_worst', 'smoothness_worst', \n",
    "         'compactness_worst', 'concavity_worst', \n",
    "         'concave_points_worst', 'symmetry_worst', \n",
    "         'fractal_dimension_worst'] \n",
    "\n",
    "df_breast_cancer = pd.read_csv(urlopen(UCI_data_URL), names=column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR TURN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 5 rows in the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the id_number column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a description of the dataframe using describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .shape to display the dimensions of our data frame\n",
    "# Expected output: (569, 31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .dtypes to display the data types of our columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the number of NA values in each column using isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visually explore our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "\n",
    "As a first example, we will try and visualize the relationship between our mean features.\n",
    "\n",
    "This heat map shows the correlation between features, with 1 signifying a high correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw a heatmap between mean features and diagnosis using Matplotlib and Seaborn\n",
    "features_mean = ['radius_mean','texture_mean','perimeter_mean','area_mean','smoothness_mean', 'compactness_mean', 'concavity_mean','concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
    "plt.figure(figsize=(15,15))\n",
    "heat = sns.heatmap(df_breast_cancer[features_mean].corr(), vmax=1, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the radius_feature as a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we split the dataset into malignant and benign.\n",
    "dataMalignant=df_breast_cancer[df_breast_cancer['diagnosis'] =='M']\n",
    "dataBenign=df_breast_cancer[df_breast_cancer['diagnosis'] ==\"B\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting as a histogram\n",
    "feature = 'radius_mean'\n",
    "fig, ax = plt.subplots()\n",
    "figsize=(15,15)\n",
    "\n",
    "binwidth= (max(df_breast_cancer[feature]) - min(df_breast_cancer[feature]))/250\n",
    "ax.hist(x = (dataMalignant[feature],dataBenign[feature]), \n",
    "        bins=np.arange(min(df_breast_cancer[feature]), max(df_breast_cancer[feature]) + binwidth, binwidth) , \n",
    "        alpha=0.5,stacked=True, normed = True, label=['M','B'],color=['r','g'])\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_title(feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TURN\n",
    "\n",
    "# Now code a loop which goes through all the other \"mean\" features and plots their histograms\n",
    "features_mean = ['texture_mean','perimeter_mean','area_mean','smoothness_mean', 'compactness_mean', 'concavity_mean','concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **strip plot** is another way of visualizing data. It plots the distribution of variables for each category as individual datapoints. For vertical strip plots (the default), distributions of continuous values are laid out parallel to the y-axis and the distinct categories are spaced out along the x-axis.\n",
    "\n",
    "Let's visualize \"radius_mean\" using strip plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.stripplot(x='diagnosis', y= 'radius_mean', data= df_breast_cancer, jitter=True, palette = 'Set1');\n",
    "plt.title('Diagnosis vs radius_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TURN\n",
    "\n",
    "# Now code a loop which goes through all the other mean features and displays their strip plots against the diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (LR)\n",
    "Don’t get confused by its name! It is a classification not a regression algorithm. \n",
    "In simple words, it predicts the probability of occurrence of an event based on some dependent variables. \n",
    "\n",
    "Since, it predicts the probability, its output values lies between 0 and 1 (as expected).\n",
    "\n",
    "**sklearn** provides us with tools to implement LR, so we'll use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing sklearn stuff\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Y = df_breast_cancer.pop('diagnosis')\n",
    "X = df_breast_cancer\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop \"id_number\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "msg = \"%s: %f (%f)\" % ('Logistic Regression', cv_results.mean(), cv_results.std())\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TURN!\n",
    "\n",
    "# Code a loop that runs every model below on our dataset and displays its accuracy\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('ANN', MLPClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOMEWORK: Display a boxplot showing the performance of each algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection and feature engineering\n",
    "\n",
    "Feature Selection is the process where you automatically or manually select those features which contribute most to your prediction variable or output in which you are interested in. Having irrelevant features in your data can decrease the accuracy of the models and make your model learn based on irrelevant features.\n",
    "\n",
    "Example:\n",
    "Correlated features in general don't improve models (although it depends on the specifics of the problem like the number of variables and the degree of correlation), but they MIGHT affect specific models negatively.\n",
    "\n",
    "Let's see it for ourselves.\n",
    "We can see on the heatmap that __radius_mean__ and __perimeter_mean__ are highly correlated. Let's drop pne of them and re-run our LR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_breast_cancer.drop(\"perimeter_mean\", axis = 1)\n",
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run our model on the new dataset\n",
    "X = new_df\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "msg = \"%s: %f (%f)\" % ('Logistic Regression', cv_results.mean(), cv_results.std())\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TURN \n",
    "\n",
    "# Drop one column for every pair of columns with a correlation greater than 0.90\n",
    "\n",
    "# Run an algorithm of your choice on the new dataset. Did it help us or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. \n",
    "\n",
    "Let's try and create a feature which tells us if whether \"radius_worst\" is greater than the average *radius_worst* or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average radius_worst\n",
    "mean_radius_worst = df_breast_cancer[\"radius_worst\"].mean()\n",
    "mean_radius_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a column where the value is 1 if \"radius_worst\" > mean, and 0 otherwise\n",
    "new_df_2 = df_breast_cancer.drop(\"radius_worst\", axis = 1)\n",
    "new_df_2 [\"radius_worst_mean\"] = np.where(df_breast_cancer['radius_worst']>=mean_radius_worst, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run our model on the new dataset\n",
    "X = new_df_2\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "msg = \"%s: %f (%f)\" % ('Logistic Regression', cv_results.mean(), cv_results.std())\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Wikipedia states that “hyperparameter tuning is choosing a set of optimal hyperparameters for a learning algorithm”. So what is a hyperparameter?\n",
    "\n",
    "A hyperparameter is a parameter whose value is set before the learning process begins.\n",
    "Examples of hyperparameters: penalty in logistic regression, depth in decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# make an array of depths to choose from, say 1 to 50\n",
    "depths = np.arange(1, 500, 10)\n",
    "\n",
    "# Create a parameter grid: map the parameter names to the values that should be searched\n",
    "# Simply a python dictionary\n",
    "# Key: parameter name\n",
    "# Value: list of values that should be searched for that parameter\n",
    "# Single key-value pair for param_grid\n",
    "param_grid = [{'max_depth':depths}]\n",
    "\n",
    "# instantiate the grid\n",
    "model = DecisionTreeClassifier(random_state=seed)\n",
    "grid = GridSearchCV(model, param_grid, cv=10, scoring='accuracy')\n",
    "\n",
    "# fit the grid with data\n",
    "X_train = df_breast_cancer\n",
    "grid.fit(X_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the best model\n",
    "\n",
    "# Single best score achieved across all params (min_samples_split)\n",
    "print(grid.best_score_)\n",
    "\n",
    "# Dictionary containing the parameters (min_samples_split) used to generate that score\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Actual model object fit with those best parameters\n",
    "# Shows default parameters that we did not specify\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try tuning the \"max_features\" hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try tuning the \"max_features\" AND \"max_depth\" hyperparameters at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"concl.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
